
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><title>Classifying a speech signal with an HMM as "four" or "five"</title><meta name="generator" content="MATLAB 7.10"><meta name="date" content="2010-08-30"><meta name="m-file" content="isolatedWordClassificationWithHmmsDemo"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>Classifying a speech signal with an HMM as "four" or "five"</h1><!--introduction--><p>Xtrain{i} is a 13 x T(i) sequence of MFCC data, where T(i) is the length</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#2">Initial Guess</a></li><li><a href="#6">Do the same thing with a tied mixture of Gaussians observation model</a></li></ul></div><pre class="codeinput">loadData(<span class="string">'data45'</span>);
nstates = 5;
setSeed(0);
Xtrain = [train4'; train5'];
ytrain = [repmat(4, numel(train4), 1) ; repmat(5, numel(train5), 1)];
[Xtrain, ytrain] = shuffleRows(Xtrain, ytrain);
Xtest = test45';
ytest = labels';
[Xtest, ytest] = shuffleRows(Xtest, ytest);
</pre><h2>Initial Guess<a name="2"></a></h2><pre class="codeinput">pi0 = [1, 0, 0, 0, 0];
transmat0 = normalize(diag(ones(nstates, 1)) + <span class="keyword">...</span>
            diag(ones(nstates-1, 1), 1), 2);
</pre><pre class="codeinput">fitArgs = {<span class="string">'pi0'</span>, pi0, <span class="string">'trans0'</span>, transmat0, <span class="string">'verbose'</span>, true};
fitFn   = @(X)hmmFit(X, nstates, <span class="string">'gauss'</span>, fitArgs{:});
model = generativeClassifierFit(fitFn, Xtrain, ytrain);
</pre><pre class="codeoutput">1	 loglik: -136774
2	 loglik: -80469.3
3	 loglik: -75503.9
4	 loglik: -73980.4
5	 loglik: -73064.5
6	 loglik: -72316.7
7	 loglik: -71873.3
8	 loglik: -71498.2
9	 loglik: -71272.6
10	 loglik: -71173.4
11	 loglik: -71122.6
12	 loglik: -71094.9
13	 loglik: -71076.1
14	 loglik: -71060.2
15	 loglik: -71046.5
16	 loglik: -71035.7
17	 loglik: -71026.6
18	 loglik: -71019.5
19	 loglik: -71014.4
1	 loglik: -150882
2	 loglik: -99493.4
3	 loglik: -89818
4	 loglik: -88251.6
5	 loglik: -88045.9
6	 loglik: -87758.7
7	 loglik: -87518.5
8	 loglik: -87350
9	 loglik: -87241.1
10	 loglik: -87097.6
11	 loglik: -86920.6
12	 loglik: -86709.8
13	 loglik: -86331.3
14	 loglik: -85693.3
15	 loglik: -85414.7
16	 loglik: -85240.7
17	 loglik: -85084.5
18	 loglik: -84537.1
19	 loglik: -83603.2
20	 loglik: -83103.2
21	 loglik: -82536.1
22	 loglik: -81826.3
23	 loglik: -81012.4
24	 loglik: -80040.7
25	 loglik: -79228.7
26	 loglik: -78719.1
27	 loglik: -78364.9
28	 loglik: -78170.4
29	 loglik: -78084.8
30	 loglik: -78032.9
31	 loglik: -77985.1
32	 loglik: -77936.6
33	 loglik: -77907.8
34	 loglik: -77881.1
35	 loglik: -77851
36	 loglik: -77795.6
37	 loglik: -77747.8
38	 loglik: -77729
39	 loglik: -77724
</pre><pre class="codeinput">logprobFn = @hmmLogprob;
[yhat, post] = generativeClassifierPredict(logprobFn, model, Xtest);
</pre><pre class="codeinput">nerrors = sum(yhat ~= ytest);
display(nerrors);
</pre><pre class="codeoutput">nerrors =
     0
</pre><h2>Do the same thing with a tied mixture of Gaussians observation model<a name="6"></a></h2><pre class="codeinput">nmix    = 3;
fitArgs = [fitArgs, {<span class="string">'nmix'</span>, nmix}];
fitFn   = @(X)hmmFit(X, nstates, <span class="string">'mixGaussTied'</span>, fitArgs{:});
model = generativeClassifierFit(fitFn, Xtrain, ytrain);
[yhat, post] = generativeClassifierPredict(logprobFn, model, Xtest);
</pre><pre class="codeoutput">1	 loglik: -134989
2	 loglik: -94883.7
3	 loglik: -90940.6
4	 loglik: -85701.5
5	 loglik: -79919
6	 loglik: -76967.8
7	 loglik: -74831.1
8	 loglik: -74062
9	 loglik: -73853.3
10	 loglik: -73759.1
11	 loglik: -73680.6
12	 loglik: -73592.9
13	 loglik: -73507.1
14	 loglik: -73447.3
15	 loglik: -73400.9
16	 loglik: -73360
17	 loglik: -73321
18	 loglik: -73281.5
19	 loglik: -73242.3
20	 loglik: -73208.8
21	 loglik: -73186.3
22	 loglik: -73171.9
23	 loglik: -73163.3
24	 loglik: -73158.2
1	 loglik: -141359
2	 loglik: -100912
3	 loglik: -98073.2
4	 loglik: -95759.7
5	 loglik: -92989.4
6	 loglik: -90696.4
7	 loglik: -89074.7
8	 loglik: -86596.1
9	 loglik: -84186.1
10	 loglik: -83301.1
11	 loglik: -83055.4
12	 loglik: -82942.5
13	 loglik: -82879.4
14	 loglik: -82814.1
15	 loglik: -82746.4
16	 loglik: -82700.7
17	 loglik: -82670.3
18	 loglik: -82647
19	 loglik: -82629
20	 loglik: -82616.1
21	 loglik: -82606.1
22	 loglik: -82596.1
23	 loglik: -82584.2
24	 loglik: -82572.2
25	 loglik: -82564.2
</pre><pre class="codeinput">nerrors = sum(yhat ~= ytest);
display(nerrors);
</pre><pre class="codeoutput">nerrors =
     0
</pre><p class="footer"><br>
      Published with MATLAB&reg; 7.10<br></p></div><!--
##### SOURCE BEGIN #####
%% Classifying a speech signal with an HMM as "four" or "five"
% Xtrain{i} is a 13 x T(i) sequence of MFCC data, where T(i) is the length
%%
loadData('data45'); 
nstates = 5;
setSeed(0); 
Xtrain = [train4'; train5'];
ytrain = [repmat(4, numel(train4), 1) ; repmat(5, numel(train5), 1)];
[Xtrain, ytrain] = shuffleRows(Xtrain, ytrain);
Xtest = test45'; 
ytest = labels'; 
[Xtest, ytest] = shuffleRows(Xtest, ytest); 
%% Initial Guess
pi0 = [1, 0, 0, 0, 0];
transmat0 = normalize(diag(ones(nstates, 1)) + ...
            diag(ones(nstates-1, 1), 1), 2);
%%        
fitArgs = {'pi0', pi0, 'trans0', transmat0, 'verbose', true};
fitFn   = @(X)hmmFit(X, nstates, 'gauss', fitArgs{:}); 
model = generativeClassifierFit(fitFn, Xtrain, ytrain); 
%%
logprobFn = @hmmLogprob;
[yhat, post] = generativeClassifierPredict(logprobFn, model, Xtest);
%%
nerrors = sum(yhat ~= ytest);
display(nerrors);


%% Do the same thing with a tied mixture of Gaussians observation model
nmix    = 3; 
fitArgs = [fitArgs, {'nmix', nmix}];
fitFn   = @(X)hmmFit(X, nstates, 'mixGaussTied', fitArgs{:}); 
model = generativeClassifierFit(fitFn, Xtrain, ytrain); 
[yhat, post] = generativeClassifierPredict(logprobFn, model, Xtest);
%%
nerrors = sum(yhat ~= ytest);
display(nerrors);



##### SOURCE END #####
--></body></html>
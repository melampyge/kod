
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><title>HMMs and the occasionally Dishonest Casino</title><meta name="generator" content="MATLAB 7.10"><meta name="date" content="2010-08-30"><meta name="m-file" content="casinoDemo"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>HMMs and the occasionally Dishonest Casino</h1><!--introduction--><p>This is an example from 'Biological Sequence Analysis: Probabilistic Models Proteins and Nucleic Acids' by Durbin, Eddy, Krogh, &amp; Mitchison, (1998) p54.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Description</a></li><li><a href="#2">Specifying the Model</a></li><li><a href="#3">Observation Model</a></li><li><a href="#4">Transition Matrix</a></li><li><a href="#5">Distribution over Starting States</a></li><li><a href="#6">Sample</a></li><li><a href="#7">Fit via EM (pretending we don't know the hidden states)</a></li><li><a href="#8">Viterbi Path</a></li><li><a href="#9">Do the same thing with a dgm</a></li><li><a href="#10">Sequence of Most Likely States (Max Marginals)</a></li><li><a href="#11">Posterior Samples</a></li></ul></div><h2>Description<a name="1"></a></h2><p>Suppose a casino uses a fair die most of the time but occasionally switches to and from a loaded die according to Markovian dynamics. We observe the dice rolls but not the type of die. We can use a Hidden Markov Model to predict which die is being used at any given point in a sequence of rolls. In this example, we know both the transition and emission probabilities.</p><h2>Specifying the Model<a name="2"></a></h2><p>Since we are not learning the parameters, we must specify the observation/emission model, the transition matrix, and the distribution over starting states.</p><pre class="codeinput">fair = 1; loaded = 2;
</pre><h2>Observation Model<a name="3"></a></h2><p>We will use a discrete observation model, one discrete distribution per hidden state of which there are two.</p><pre class="codeinput">setSeed(1);
obsModel = [1/6 , 1/6 , 1/6 , 1/6 , 1/6 , 1/6  ;   <span class="comment">% fair die</span>
           1/10, 1/10, 1/10, 1/10, 1/10, 5/10 ];   <span class="comment">% loaded die</span>
</pre><h2>Transition Matrix<a name="4"></a></h2><pre class="codeinput">transmat = [0.95 , 0.05;
           0.10  , 0.90];
</pre><h2>Distribution over Starting States<a name="5"></a></h2><pre class="codeinput">pi = [0.5, 0.5];
</pre><h2>Sample<a name="6"></a></h2><p>We now sample a single sequence of 300 dice rolls</p><pre class="codeinput">len = 300; nsamples = 1;
markov.pi = pi;
markov.A = transmat;
hidden = markovSample(markov, len, nsamples);
observed = zeros(1, len);
<span class="keyword">for</span> t=1:len
   observed(1, t) = sampleDiscrete(obsModel(hidden(t), :));
<span class="keyword">end</span>
</pre><h2>Fit via EM (pretending we don't know the hidden states)<a name="7"></a></h2><pre class="codeinput">nstates = size(obsModel, 1);
modelEM = hmmFit(observed, nstates, <span class="string">'discrete'</span>, <span class="keyword">...</span>
    <span class="string">'maxIter'</span>, 1000, <span class="string">'verbose'</span>, true, <span class="string">'convTol'</span>, 1e-7, <span class="string">'nRandomRestarts'</span>, 3);
</pre><pre class="codeoutput">
********** Random Restart 1 **********
1	 loglik: -547.632
2	 loglik: -544.955
3	 loglik: -544.691
4	 loglik: -544.495
5	 loglik: -544.341
6	 loglik: -544.218
7	 loglik: -544.116
8	 loglik: -544.032
9	 loglik: -543.959
10	 loglik: -543.897
11	 loglik: -543.843
12	 loglik: -543.794
13	 loglik: -543.751
14	 loglik: -543.711
15	 loglik: -543.675
16	 loglik: -543.641
17	 loglik: -543.609
18	 loglik: -543.579
19	 loglik: -543.549
20	 loglik: -543.521
21	 loglik: -543.493
22	 loglik: -543.465
23	 loglik: -543.437
24	 loglik: -543.408
25	 loglik: -543.379
26	 loglik: -543.348
27	 loglik: -543.315
28	 loglik: -543.28
29	 loglik: -543.242
30	 loglik: -543.199
31	 loglik: -543.151
32	 loglik: -543.096
33	 loglik: -543.031
34	 loglik: -542.955
35	 loglik: -542.862
36	 loglik: -542.747
37	 loglik: -542.604
38	 loglik: -542.423
39	 loglik: -542.19
40	 loglik: -541.892
41	 loglik: -541.512
42	 loglik: -541.044
43	 loglik: -540.498
44	 loglik: -539.913
45	 loglik: -539.355
46	 loglik: -538.885
47	 loglik: -538.527
48	 loglik: -538.268
49	 loglik: -538.078
50	 loglik: -537.927
51	 loglik: -537.799
52	 loglik: -537.683
53	 loglik: -537.577
54	 loglik: -537.478
55	 loglik: -537.386
56	 loglik: -537.302
57	 loglik: -537.224
58	 loglik: -537.153
59	 loglik: -537.088
60	 loglik: -537.03
61	 loglik: -536.978
62	 loglik: -536.932
63	 loglik: -536.891
64	 loglik: -536.856
65	 loglik: -536.825
66	 loglik: -536.798
67	 loglik: -536.775
68	 loglik: -536.756
69	 loglik: -536.74
70	 loglik: -536.726
71	 loglik: -536.715
72	 loglik: -536.706
73	 loglik: -536.698
74	 loglik: -536.692
75	 loglik: -536.687
76	 loglik: -536.683
77	 loglik: -536.68
78	 loglik: -536.678
79	 loglik: -536.675
80	 loglik: -536.674
81	 loglik: -536.673
82	 loglik: -536.672
83	 loglik: -536.671
84	 loglik: -536.67
85	 loglik: -536.67
86	 loglik: -536.669
87	 loglik: -536.669
88	 loglik: -536.669
89	 loglik: -536.669
90	 loglik: -536.669
91	 loglik: -536.668
92	 loglik: -536.668
93	 loglik: -536.668
94	 loglik: -536.668

********** Random Restart 2 **********
1	 loglik: -581.387
2	 loglik: -543.978
3	 loglik: -543.878
4	 loglik: -543.797
5	 loglik: -543.728
6	 loglik: -543.668
7	 loglik: -543.617
8	 loglik: -543.572
9	 loglik: -543.533
10	 loglik: -543.499
11	 loglik: -543.47
12	 loglik: -543.443
13	 loglik: -543.42
14	 loglik: -543.4
15	 loglik: -543.382
16	 loglik: -543.365
17	 loglik: -543.351
18	 loglik: -543.338
19	 loglik: -543.327
20	 loglik: -543.317
21	 loglik: -543.307
22	 loglik: -543.299
23	 loglik: -543.292
24	 loglik: -543.285
25	 loglik: -543.279
26	 loglik: -543.274
27	 loglik: -543.269
28	 loglik: -543.265
29	 loglik: -543.261
30	 loglik: -543.257
31	 loglik: -543.254
32	 loglik: -543.251
33	 loglik: -543.249
34	 loglik: -543.246
35	 loglik: -543.244
36	 loglik: -543.242
37	 loglik: -543.24
38	 loglik: -543.239
39	 loglik: -543.237
40	 loglik: -543.236
41	 loglik: -543.235
42	 loglik: -543.233
43	 loglik: -543.232
44	 loglik: -543.231
45	 loglik: -543.231
46	 loglik: -543.23
47	 loglik: -543.229
48	 loglik: -543.229
49	 loglik: -543.228
50	 loglik: -543.227
51	 loglik: -543.227
52	 loglik: -543.226
53	 loglik: -543.226
54	 loglik: -543.226
55	 loglik: -543.225
56	 loglik: -543.225
57	 loglik: -543.225
58	 loglik: -543.224
59	 loglik: -543.224
60	 loglik: -543.224
61	 loglik: -543.224
62	 loglik: -543.224
63	 loglik: -543.223
64	 loglik: -543.223
65	 loglik: -543.223
66	 loglik: -543.223
67	 loglik: -543.223
68	 loglik: -543.223
69	 loglik: -543.223
70	 loglik: -543.223
71	 loglik: -543.222
72	 loglik: -543.222
73	 loglik: -543.222
74	 loglik: -543.222
75	 loglik: -543.222
76	 loglik: -543.222
77	 loglik: -543.222
78	 loglik: -543.222

********** Random Restart 3 **********
1	 loglik: -612.429
2	 loglik: -544.386
3	 loglik: -544.229
4	 loglik: -544.109
5	 loglik: -544.007
6	 loglik: -543.921
7	 loglik: -543.846
8	 loglik: -543.78
9	 loglik: -543.723
10	 loglik: -543.673
11	 loglik: -543.629
12	 loglik: -543.59
13	 loglik: -543.555
14	 loglik: -543.524
15	 loglik: -543.496
16	 loglik: -543.472
17	 loglik: -543.45
18	 loglik: -543.43
19	 loglik: -543.412
20	 loglik: -543.396
21	 loglik: -543.381
22	 loglik: -543.368
23	 loglik: -543.357
24	 loglik: -543.346
25	 loglik: -543.337
26	 loglik: -543.328
27	 loglik: -543.32
28	 loglik: -543.313
29	 loglik: -543.306
30	 loglik: -543.301
31	 loglik: -543.295
32	 loglik: -543.29
33	 loglik: -543.286
34	 loglik: -543.282
35	 loglik: -543.278
36	 loglik: -543.275
37	 loglik: -543.272
38	 loglik: -543.269
39	 loglik: -543.266
40	 loglik: -543.264
41	 loglik: -543.262
42	 loglik: -543.26
43	 loglik: -543.258
44	 loglik: -543.256
45	 loglik: -543.255
46	 loglik: -543.253
47	 loglik: -543.252
48	 loglik: -543.25
49	 loglik: -543.249
50	 loglik: -543.248
51	 loglik: -543.247
52	 loglik: -543.246
53	 loglik: -543.245
54	 loglik: -543.244
55	 loglik: -543.244
56	 loglik: -543.243
57	 loglik: -543.242
58	 loglik: -543.242
59	 loglik: -543.241
60	 loglik: -543.24
61	 loglik: -543.24
62	 loglik: -543.239
63	 loglik: -543.239
64	 loglik: -543.238
65	 loglik: -543.238
66	 loglik: -543.237
67	 loglik: -543.237
68	 loglik: -543.236
69	 loglik: -543.236
70	 loglik: -543.236
71	 loglik: -543.235
72	 loglik: -543.235
73	 loglik: -543.235
74	 loglik: -543.234
75	 loglik: -543.234
76	 loglik: -543.234
77	 loglik: -543.233
78	 loglik: -543.233
79	 loglik: -543.233
80	 loglik: -543.232
81	 loglik: -543.232
82	 loglik: -543.232
83	 loglik: -543.232
84	 loglik: -543.231
85	 loglik: -543.231
86	 loglik: -543.231
87	 loglik: -543.231
88	 loglik: -543.231
89	 loglik: -543.23
90	 loglik: -543.23
91	 loglik: -543.23
92	 loglik: -543.23
93	 loglik: -543.23
94	 loglik: -543.229
95	 loglik: -543.229
96	 loglik: -543.229
97	 loglik: -543.229
98	 loglik: -543.229
99	 loglik: -543.229
100	 loglik: -543.228
101	 loglik: -543.228
102	 loglik: -543.228
103	 loglik: -543.228
104	 loglik: -543.228
105	 loglik: -543.228
106	 loglik: -543.228
107	 loglik: -543.227
108	 loglik: -543.227
109	 loglik: -543.227
110	 loglik: -543.227
111	 loglik: -543.227
112	 loglik: -543.227
113	 loglik: -543.227
114	 loglik: -543.227
115	 loglik: -543.227
116	 loglik: -543.226
117	 loglik: -543.226
118	 loglik: -543.226
119	 loglik: -543.226
120	 loglik: -543.226
121	 loglik: -543.226
122	 loglik: -543.226
123	 loglik: -543.226
124	 loglik: -543.226
125	 loglik: -543.226
126	 loglik: -543.225
127	 loglik: -543.225
128	 loglik: -543.225
129	 loglik: -543.225
130	 loglik: -543.225
131	 loglik: -543.225
132	 loglik: -543.225
133	 loglik: -543.225
134	 loglik: -543.225
135	 loglik: -543.225
136	 loglik: -543.225
137	 loglik: -543.225
138	 loglik: -543.225
139	 loglik: -543.224
140	 loglik: -543.224
141	 loglik: -543.224
142	 loglik: -543.224
143	 loglik: -543.224
144	 loglik: -543.224
145	 loglik: -543.224
146	 loglik: -543.224
147	 loglik: -543.224
148	 loglik: -543.224
149	 loglik: -543.224
150	 loglik: -543.224
151	 loglik: -543.224
</pre><h2>Viterbi Path<a name="8"></a></h2><p>We can now try and recover the most likely sequence of hidden states, the Viterbi path.</p><pre class="codeinput">model.nObsStates = size(obsModel, 2);
model.emission = tabularCpdCreate(obsModel);
model.nstates = nstates;
model.pi = pi;
model.A = transmat;
model.type = <span class="string">'discrete'</span>;
viterbiPath = hmmMap(model, observed);
</pre><h2>Do the same thing with a dgm<a name="9"></a></h2><pre class="codeinput">dgm = hmmToDgm(model, len);
viterbiPathDGM = dgmMap(dgm, <span class="string">'localev'</span>, observed);
assert(isequal(viterbiPath, viterbiPathDGM));
</pre><h2>Sequence of Most Likely States (Max Marginals)<a name="10"></a></h2><pre class="codeinput">[gamma, loglik, alpha, beta, localEvidence]  = hmmInferNodes(model, observed);
maxmargF = maxidx(alpha); <span class="comment">% filtered (forwards pass only)</span>
maxmarg = maxidx(gamma);  <span class="comment">% smoothed (forwards backwards)</span>
</pre><h2>Posterior Samples<a name="11"></a></h2><p>We can also sample from the posterior, fowards filtering, backwards sampling, and compare the mode of these samples to the predictions above.</p><pre class="codeinput">postSamp = mode(hmmSamplePost(model, observed, 100), 2)';
</pre><p>We now display the rolls, the corresponding die used and the Viterbi prediction.</p><pre class="codeinput">    die = hidden;
    rolls = observed;
    dielabel = repmat(<span class="string">'F'</span>,size(die));
    dielabel(die == 2) = <span class="string">'L'</span>;
    vitlabel = repmat(<span class="string">'F'</span>,size(viterbiPath));
    vitlabel(viterbiPath == 2) = <span class="string">'L'</span>;
    maxmarglabel = repmat(<span class="string">'F'</span>,size(maxmarg));
    maxmarglabel(maxmarg == 2) = <span class="string">'L'</span>;
    postsamplabel = repmat(<span class="string">'F'</span>,size(postSamp));
    postsamplabel(postSamp == 2) = <span class="string">'L'</span>;
    rollLabel = num2str(rolls);
    rollLabel(rollLabel == <span class="string">' '</span>) = [];
    <span class="keyword">for</span> i=1:60:300
        fprintf(<span class="string">'Rolls:\t  %s\n'</span>,rollLabel(i:i+59));
        fprintf(<span class="string">'Die:\t  %s\n'</span>,dielabel(i:i+59));
        fprintf(<span class="string">'Viterbi:  %s\n'</span>,vitlabel(i:i+59));
        fprintf(<span class="string">'MaxMarg:  %s\n'</span>,maxmarglabel(i:i+59));
        fprintf(<span class="string">'PostSamp: %s\n\n'</span>,postsamplabel(i:i+59));
    <span class="keyword">end</span>
</pre><pre class="codeoutput">Rolls:	  565413324266212352263632651444153661466466661666615522435356
Die:	  FFFFFFFFFFFFFFFFFFFFFLLLLLFFFFFFLLLLLLFFLLLLLLLLLLFFFFFFFFFF
Viterbi:  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFLLLLLLLLLLLLLLLLFFFFFFFFFFF
MaxMarg:  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFLLLLLLLLLLLLLLLLFFFFFFFFFFF
PostSamp: FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFLLLLLLLLLLLLLLLLFFFFFFFFFFF

Rolls:	  216464644131151365523462225516363166464465153622152666536354
Die:	  FFFFFFFFFFFFFFFFFFFFFFFFFFFLLLLLLLLLLLFFFFFFFFFFFLLLLLFFFFFF
Viterbi:  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
MaxMarg:  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFLLLLLLLFFFFFFFFFFFFFLLLFFFFFF
PostSamp: FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFLLLLLLLFFFFFFFFFFFFFLLLFFFFFF

Rolls:	  111131153535535361514141665611266666653226236262426456616614
Die:	  FFFFFFFFFFFLLFFFFFFFFFFFFFFFFFFLLLLLLLLLLLLLLFFFFFFLLLLLLLFF
Viterbi:  FFFFFFFFFFFFFFFFFFFFFFFFLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLFF
MaxMarg:  FFFFFFFFFFFFFFFFFFFFFFFFLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLFF
PostSamp: FFFFFFFFFFFFFFFFFFFFFFFFLLLLLLLLLLLLLLLFFFFFLFLFFLLLLLLLLLLF

Rolls:	  264534214246323666621342656263641365424654664111336265545313
Die:	  FFFFFFFFFFFFFFFFFFFFLLLLLLLLLLLLLLLLFFFFFFFFFFFFFFFFFFFFFFFF
Viterbi:  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
MaxMarg:  FFFFFFFFFFFFFFLLLLLLFFFFLLLLLLLFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
PostSamp: FFFFFFFFFFFFFFLLLLLLFFFFLLLLLLLFFFFFFFFFFFFFFFFFFFFFFFFFFFFF

Rolls:	  353311526236652466621661665661566666366462636564364663321312
Die:	  FFFFFFFFFFFLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLFFFLL
Viterbi:  FFFFFFFFFFFLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLFFFFFFF
MaxMarg:  FFFFFFFFFFFLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLFFFFFFF
PostSamp: FFFFFFFFFFLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLFFFFFFF

</pre><pre class="codeinput">viterbiErr  =  sum(viterbiPath ~= die);
maxMargSErr =  sum(maxmarg ~= die);
maxMargFErr =  sum(maxmargF~=die);
postSampErr    =  sum(postSamp ~= die);
fprintf(<span class="string">'\nNumber of Errors\n'</span>);
fprintf(<span class="string">'Viterbi:\t\t\t\t%d/%d\n'</span>,viterbiErr,300);
fprintf(<span class="string">'Max Marginal Smoothed:  %d/%d\n'</span>,maxMargSErr,300);
fprintf(<span class="string">'Max Marginal Filtered:  %d/%d\n'</span>,maxMargFErr,300);
fprintf(<span class="string">'Mode Posterior Samples: %d/%d\n'</span>,postSampErr,300);
</pre><pre class="codeoutput">
Number of Errors
Viterbi:				60/300
Max Marginal Smoothed:  49/300
Max Marginal Filtered:  71/300
Mode Posterior Samples: 53/300
</pre><p>Here we plot the probabilities and shade in grey the portions of the die sequence where a loaded die was actually used.</p><pre class="codeinput">    figure; hold <span class="string">on</span>;
    <span class="comment">% fair=1, loaded=2. So die-1=0 for fair, so gray=loaded</span>
    area(die-1,<span class="string">'FaceColor'</span>,0.75*ones(1,3),<span class="string">'EdgeColor'</span>,ones(1,3));
    plot(alpha(loaded,:),<span class="string">'LineWidth'</span>,2.5);
    xlabel(<span class="string">'roll number'</span>);
    ylabel(<span class="string">'p(loaded)'</span>);
    set(gca,<span class="string">'YTick'</span>,0:0.5:1);
    title(sprintf(<span class="string">'filtered'</span>));
    printPmtkFigure <span class="string">hmmCasinoFiltered</span>

    figure; hold <span class="string">on</span>;
    area(die-1,<span class="string">'FaceColor'</span>,0.75*ones(1,3),<span class="string">'EdgeColor'</span>,ones(1,3));
    plot(gamma(loaded,:),<span class="string">'LineWidth'</span>,2.5);
    xlabel(<span class="string">'roll number'</span>);
    ylabel(<span class="string">'p(loaded)'</span>);
    set(gca,<span class="string">'YTick'</span>,0:0.5:1);
    title(sprintf(<span class="string">'smoothed'</span>));
    printPmtkFigure <span class="string">'hmmCasinoSmoothed'</span>

    figure; hold <span class="string">on</span>;
    area(die-1,<span class="string">'FaceColor'</span>,0.75*ones(1,3),<span class="string">'EdgeColor'</span>,ones(1,3));
    plot(viterbiPath-1, <span class="string">'linewidth'</span>, 2.5);
    xlabel(<span class="string">'roll number'</span>);
    ylabel(<span class="string">'MAP state (0=fair,1=loaded)'</span>);
    set(gca,<span class="string">'YTick'</span>,0:0.5:1);
    title(sprintf(<span class="string">'Viterbi'</span>));
    printPmtkFigure <span class="string">hmmCasinoViterbi</span>
</pre><img vspace="5" hspace="5" src="casinoDemo_01.png" alt=""> <img vspace="5" hspace="5" src="casinoDemo_02.png" alt=""> <img vspace="5" hspace="5" src="casinoDemo_03.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.10<br></p></div><!--
##### SOURCE BEGIN #####
%% HMMs and the occasionally Dishonest Casino
% This is an example from 'Biological Sequence Analysis: 
% Probabilistic Models Proteins and Nucleic Acids' by Durbin, Eddy, Krogh, &
% Mitchison, (1998) p54.
%% Description
% Suppose a casino uses a fair die most of the time but occasionally
% switches to and from a loaded die according to Markovian dynamics. We
% observe the dice rolls but not the type of die. We can use a Hidden
% Markov Model to predict which die is being used at any given point in a
% sequence of rolls. In this example, we know both the transition and
% emission probabilities. 
%% Specifying the Model
% Since we are not learning the parameters, we must specify the
% observation/emission model, the transition matrix, and the distribution 
% over starting states.
fair = 1; loaded = 2;
%% Observation Model  
% We will use a discrete observation model, one discrete distribution per
% hidden state of which there are two. 
setSeed(1);
obsModel = [1/6 , 1/6 , 1/6 , 1/6 , 1/6 , 1/6  ;   % fair die
           1/10, 1/10, 1/10, 1/10, 1/10, 5/10 ];   % loaded die
%% Transition Matrix
% 
transmat = [0.95 , 0.05;
           0.10  , 0.90];
%% Distribution over Starting States      
pi = [0.5, 0.5];
%% Sample
% We now sample a single sequence of 300 dice rolls    
len = 300; nsamples = 1;
markov.pi = pi;
markov.A = transmat;
hidden = markovSample(markov, len, nsamples);
observed = zeros(1, len); 
for t=1:len
   observed(1, t) = sampleDiscrete(obsModel(hidden(t), :)); 
end
%% Fit via EM (pretending we don't know the hidden states)
nstates = size(obsModel, 1);
modelEM = hmmFit(observed, nstates, 'discrete', ...
    'maxIter', 1000, 'verbose', true, 'convTol', 1e-7, 'nRandomRestarts', 3);
%% Viterbi Path
% We can now try and recover the most likely sequence of hidden states, 
% the Viterbi path. 

model.nObsStates = size(obsModel, 2); 
model.emission = tabularCpdCreate(obsModel);
model.nstates = nstates;
model.pi = pi;
model.A = transmat; 
model.type = 'discrete';
viterbiPath = hmmMap(model, observed);
%% Do the same thing with a dgm
dgm = hmmToDgm(model, len); 
viterbiPathDGM = dgmMap(dgm, 'localev', observed);
assert(isequal(viterbiPath, viterbiPathDGM)); 
%% Sequence of Most Likely States (Max Marginals)
[gamma, loglik, alpha, beta, localEvidence]  = hmmInferNodes(model, observed);
maxmargF = maxidx(alpha); % filtered (forwards pass only)
maxmarg = maxidx(gamma);  % smoothed (forwards backwards)
%% Posterior Samples
% We can also sample from the posterior, fowards filtering, backwards sampling,
% and compare the mode of these samples to the predictions above. 
postSamp = mode(hmmSamplePost(model, observed, 100), 2)';
%%
% We now display the rolls, the corresponding die used and the Viterbi 
% prediction. 
    die = hidden;
    rolls = observed; 
    dielabel = repmat('F',size(die));
    dielabel(die == 2) = 'L';
    vitlabel = repmat('F',size(viterbiPath));
    vitlabel(viterbiPath == 2) = 'L';
    maxmarglabel = repmat('F',size(maxmarg));
    maxmarglabel(maxmarg == 2) = 'L';
    postsamplabel = repmat('F',size(postSamp));
    postsamplabel(postSamp == 2) = 'L';
    rollLabel = num2str(rolls);
    rollLabel(rollLabel == ' ') = [];
    for i=1:60:300
        fprintf('Rolls:\t  %s\n',rollLabel(i:i+59));
        fprintf('Die:\t  %s\n',dielabel(i:i+59));
        fprintf('Viterbi:  %s\n',vitlabel(i:i+59));
        fprintf('MaxMarg:  %s\n',maxmarglabel(i:i+59));
        fprintf('PostSamp: %s\n\n',postsamplabel(i:i+59));
    end
    
%%
viterbiErr  =  sum(viterbiPath ~= die);
maxMargSErr =  sum(maxmarg ~= die);
maxMargFErr =  sum(maxmargF~=die);
postSampErr    =  sum(postSamp ~= die);
fprintf('\nNumber of Errors\n');
fprintf('Viterbi:\t\t\t\t%d/%d\n',viterbiErr,300);
fprintf('Max Marginal Smoothed:  %d/%d\n',maxMargSErr,300);
fprintf('Max Marginal Filtered:  %d/%d\n',maxMargFErr,300);
fprintf('Mode Posterior Samples: %d/%d\n',postSampErr,300);

%% 
% Here we plot the probabilities and shade in grey the portions of the die
% sequence where a loaded die was actually used. 
    figure; hold on;
    % fair=1, loaded=2. So die-1=0 for fair, so gray=loaded
    area(die-1,'FaceColor',0.75*ones(1,3),'EdgeColor',ones(1,3));
    plot(alpha(loaded,:),'LineWidth',2.5);
    xlabel('roll number');
    ylabel('p(loaded)');
    set(gca,'YTick',0:0.5:1);
    title(sprintf('filtered'));
    printPmtkFigure hmmCasinoFiltered
    
    figure; hold on;
    area(die-1,'FaceColor',0.75*ones(1,3),'EdgeColor',ones(1,3));
    plot(gamma(loaded,:),'LineWidth',2.5);
    xlabel('roll number');
    ylabel('p(loaded)');
    set(gca,'YTick',0:0.5:1);
    title(sprintf('smoothed'));
    printPmtkFigure 'hmmCasinoSmoothed'
    
    figure; hold on;
    area(die-1,'FaceColor',0.75*ones(1,3),'EdgeColor',ones(1,3));
    plot(viterbiPath-1, 'linewidth', 2.5);
    xlabel('roll number');
    ylabel('MAP state (0=fair,1=loaded)');
    set(gca,'YTick',0:0.5:1);
    title(sprintf('Viterbi'));
    printPmtkFigure hmmCasinoViterbi
%%
##### SOURCE END #####
--></body></html>